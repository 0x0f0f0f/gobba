\documentclass[a4paper, 10pt]{article}

%% Language and font encodings. This says how to do hyphenation on end of lines.
\usepackage[english]{babel}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{caption}
\usepackage{mathtools}
\usepackage{amsthm}
\usepackage[title]{appendix}
\usepackage{collectbox}
%\usepackage{tgpagella} % text only
%\usepackage{mathpazo}
\usepackage{stix2}

\usepackage{multicol}
\setlength{\columnsep}{1.5cm}
\setlength{\columnseprule}{0.5pt}
%\usepackage{aas_macros}

%% Sets page size and margins. You can edit this to your liking
\usepackage[top=1.3cm, bottom=2.0cm, outer=1.2cm, inner=1.2cm, heightrounded,
marginparwidth=1cm, marginparsep=0.4cm]{geometry}

%% Useful packages
\usepackage{graphicx} %allows you to use jpg or png images. PDF is still recommended
\usepackage[colorlinks=False]{hyperref} % add links inside PDF files
\usepackage{amsmath}  % Math fonts
\usepackage{amsfonts} %
\usepackage{amssymb}  %

\definecolor{vgreen}{RGB}{104,180,104}
\definecolor{vblue}{RGB}{49,49,255}
\definecolor{vorange}{RGB}{255,143,102}
\lstdefinestyle{bash} {language=bash, basicstyle=\ttfamily,
	keywordstyle=\color{vblue}, identifierstyle=\color{black},
	commentstyle=\color{vgreen}, tabsize=4,
%	moredelim=*[s][\colorIndex]{[}{]},
	literate=*{:}{:}1}

\lstdefinestyle{caml} {language=caml, basicstyle=\ttfamily, columns=[c]fixed,
 keywordstyle=\color{vblue}, identifierstyle=\color{black},
 commentstyle=\color{vgreen}, upquote=true, commentstyle=, breaklines=true,
 showstringspaces=false, stringstyle=\color{blue}, tabsize=2,
 literate={'"'}{\textquotesingle "\textquotesingle}3}

\lstdefinestyle{txt} {basicstyle=\ttfamily, columns=[c]fixed,
 keywordstyle=\color{vblue}, identifierstyle=\color{black},
 commentstyle=\color{vgreen}, upquote=true, commentstyle=, breaklines=true,
 showstringspaces=false, stringstyle=\color{blue},
 literate={'"'}{\textquotesingle "\textquotesingle}3}


%% Citation package
%\usepackage[authoryear]{natbib}
\bibliographystyle{unsrt}
%\setcitestyle{authoryear,open={(},close={)}}

\newcommand{\te}[1]{\text{#1}}
\newcommand{\mybox}{%
    \collectbox{%
        \setlength{\fboxsep}{1pt}%
        \fbox{\BOXCONTENT}%
    }%
}
\def\C{\mathbb{C}}
\def\N{\mathbb{N}}
\def\Q{\mathbb{Q}}
\def\R{\mathbb{R}}
\def\Z{\mathbb{Z}}
\DeclarePairedDelimiter\abs{\lvert}{\rvert}

\theoremstyle{plain}% default
\newtheorem{thm}{Theorem}[section]
\newtheorem{lem}[thm]{Lemma}
\newtheorem{prop}[thm]{Proposition}
\newtheorem*{cor}{Corollary}
\theoremstyle{definition}
\newtheorem{defn}{Definition}[section]
\newtheorem{conj}{Conjecture}[section]
\newtheorem{exmp}{Example}[section]
\newtheorem{exrc}[exmp]{Exercise}
\theoremstyle{remark}
\newtheorem*{comm}{Comment}
\newtheorem*{note}{Note}
\newtheorem{caso}{Case}

\title{The gobba functional programming language.\\WORK IN PROGRESS DRAFT}
\author{Alessandro Cheli\\Course taught by Prof. Gianluigi Ferrari\\and Prof. Francesca Levi}

\begin{document}
\maketitle

\begin{figure}[htbp!]
	\centering
	\includegraphics[width=0.15\textwidth]{../assets/gobba.png}
	\captionsetup{labelformat=empty}
	\caption{The gobba logo by Kevin Fontanari}
\end{figure}

\begin{abstract}
\textbf{gobba} is a dynamically typed and purely functional interpreted
programming language. It is based on the Professor Gianluigi Ferrari and
Professor Francesca Levi's minicaml, an evaluation example to show students
attending the Programming 2 course at the University of Pisa how interpreters
work. It is an interpreted language heavily inspired from the OCaml, Haskell and
Scheme languages, with static (lexical scoping), a simple but effective module
system, eager and lazy evaluation and a didactical REPL that shows each AST
expression and each evaluation step.
\end{abstract}

\section{REPL and command line interface}
\subsection{Installation}

The easiest way to install gobba is with the
OCaml package manager \textbf{opam} (\url{https://opam.ocaml.org/}). gobba is available in the opam 2.0 repository; to install the language from opam, please check that you have a version of opam $\geq$
2.0.0 and run:
\begin{lstlisting}[style=bash]
opam install gobba
\end{lstlisting}
Alternatively, \textbf{gobba} can be installed from source by downloading the
source code repository and building it manually. \textbf{gobba} has been tested
only on Linux and macOS systems. It has not been tested yet on Windows and BSD
derived systems.
\begin{lstlisting}[style=bash]
# download the source code
git clone https://github.com/0x0f0f0f/gobba
# cd into the source code directory
cd gobba
# install dependencies
opam install ANSITerminal dune ppx_deriving menhir \\
  cmdliner alcotest bisect_ppx ocamline
# compile
make
# test, execute and install
make test; make run; make install
\end{lstlisting}

\clearpage

\begin{multicols}{2}

\section{Syntax and Parser}
Lexing is achieved with \texttt{ocamllex}, the default tool for generating
scanners in OCaml.
The parser is realized with the \textbf{Menhir} parser generator, and is
documented using \textbf{Obelisk}, which generates a clean text file
containing the language grammar, available in Appendix \ref{grammar}.

\section{Purity Inference}
An important feature of the gobba language is the purity inference algorithm,
which is performed statically on expressions before evaluation. It is an interpretation of expressions over the domain of purity, meant to
prevent side effects by signal an error if they are contained inside the
programs written in the language. Expressions are tagged by the algorithm with
the \texttt{Pure}, \texttt{Impure} and \texttt{Numerical} labels. An
\texttt{Impure} expression is an expression that contains calls to primitives
that perform I/O operations, mutable variables and/or imperative style
assignments. A \texttt{Numerical} expression is an expression where only
numerical operations are performed; \texttt{Pure} expressions are those which do not fall into the previous two
categories.

To achieve the execution of impure side effects, the programmer has two constructs
available called \textbf{purity blocks}. By default, the evaluator is in an
\texttt{Uncertain} context, which means that it will not allow side effects to
be carried on by evaluation, but will allow evaluating purity blocks that change
the currently allowed purity context. The \texttt{impure} statement takes an
expression (the block) and evaluates it in a context where the allowed purity is
\texttt{Impure}, so that side effects may be performed. The other construct
available, the \texttt{pure} statement, takes an expression and enforces a
\texttt{Pure} context, meaning that side effects and nested impure blocks will
not be allowed inside of the expression.

\section{AST Optimization}
After purity inference is performed, and before evaluation, AST expressions are analyzed and optimized by an
optimizer function that is recursively called over the tree that is representing
the expression. The optimizer simplifies expressions which result is known and
therefore does not need to be evaluated. For example, it is known that \texttt{5
+ 3 $\equiv$ 8} and \texttt{true \&\& (true || (false \&\& false)) $\equiv$
true}. When a programmer writes a program, she or he may not want to do all the
simple calculations before writing the program in which they appear in, we rely
on machines to simplify those processes. Reducing constants before evaluation
may seem unnecessary when writing a small program, but they do take away
computation time, and if they appear inside of loops, it is a wise choice to
simplify those constant expressions whose result is already known before it is
calculated in all the loop iterations. It is also necessary in optimizing
programs before compilation. The optimizer, by now, reduces operations between
constants and \texttt{if} statements whose guard is always true (or false). To
achieve minimization to an unreducible form, optimizer calls are repeated until
it produces an output equal to its input; this way, we get a tree representing
an expression that cannot be optimized again. This process is fairly easy:

\begin{lstlisting}[style=caml]
let rec iterate_optimizer e =
  let oe = optimize e in
  if oe = e then e (* Bottoms out *)
  else iterate_optimizer oe
\end{lstlisting}

Boolean operations are reduced using laws from the propositional calculus, such as DeMorgan's law, complement, absorption and other trivial ones.

\section{Types}

\section{Evaluator}
\texttt{gobba}'s evaluator is heavily inspired by the Metacircular Evaluator defined in the
highly acclaimed textbook \textit{Structure and Interpretation of Computer Programs} \cite{Abelson1996}.

\section{Primitives}
The language primitives that are implemented in OCaml are organized in modules
separated by functionality. Each primitive is a function that accepts a list of
evaluated values and returns a single reduced value; therefore they have a type
of \texttt{evt list -> evt}. OCaml primitives have to perform internal
typechecking and unpacking of the arguments they receive from the gobba
calls.

From the evaluator's perspective, primitives are organized in a table
such that when a symbol gets evaluated, it is looked up in the primitives table,
if there is a match then the found primitive's name is wrapped in an
\texttt{ApplyPrimitive} expression nestedinside of a lazy lambda expression that
permits partial application. When the evaluator finally encounters an
\texttt{ApplyPrimitive} expression, the primitive OCaml function is extracted,
applied to the arguments and the resulting value is returned by the current
evaluator call. If a primitive is not found when looking up for a symbol, then a
symbol lookup is performed in the current environment.

Some primitives, such as catamorphic procedures, are not native OCaml functions
but small expressions written directly in gobba; those primitives are kept as
lazy expressions into the same table as native OCaml primitives. The key
difference between the two resides in the fact that those textual gobba
primitives are not transformed into a function which body contains only an
\texttt{ApplyPrimitive} call, but are instead parsed and analyzed at run time.
The resulting additional startup time caused by parsing and analysis is
proportional to the number of textual form primitives in the table and therefore
quite irrelevant on non-embedded computer systems. The \textit{fold left} and
\textit{fold right} catamorphic primitives are written directly in the gobba
language and are hereby provided as examples.

\begin{lstlisting}[style=caml,caption=The tail recursive left fold procedure]
fun f z l ->
if typeof l = "list" then
  let aux = fun f z l ->
    if l = [] then z else
	  aux f (f z (head l)) (tail l)
	in aux f z l
else if typeof l = "dict" then
	let aux = fun f z kl vl ->
		if kl = [] && vl = [] then z else
		aux f (f z (head vl)) (tail kl) (tail vl)
	in aux f z (getkeys l) (getvalues l)
else failwith "value is not iterable"
\end{lstlisting}

\begin{lstlisting}[style=caml,caption=The right fold procedure]
fun f z l ->
if typeof l = "list" then
   let aux = fun f z l ->
	  if l = [] then z else
	  f (head l) (aux f z (tail l))
   in aux f z l
else if typeof l = "dict" then
   let aux = fun f z kl vl ->
	  if kl = [] && vl = [] then z else
	  f (head vl) (aux f z (tail kl) (tail vl))
   in aux f z (getkeys l) (getvalues l)
else failwith "value is not iterable"
\end{lstlisting}


\section{Tests}
Unit testing is extensively performed using the alcotest testing framework. Code
coverage is provided by the \texttt{bisect\_ppx} library which yields an HTML
page containing the coverage percentage when unit tests are run by the dune
build system. After each commit is pushed to the remote version control repository on
Github, the package is built and tests are run thanks to the Travis Continuos
Integration system.

\section{Thanks to}

\begin{itemize}
	\item Prof. Gian-Luigi Ferrari and Francesca Levi for teaching us how to project and develop
	interpreters in OCaml
	\item Kevin Fontanari for the pixel art gobba mascotte.
	\item Antonio DeLucreziis for helping me implement lazy evaluation.
	\item Prof. Alessandro Berarducci for helping me study lambda calculus in deep.
	\item Giorgio Mossa for helping me polish the lambda-closure mechanism.
\end{itemize}

\end{multicols}

\iffalse
\subsection{Operational Semantics}

\begin{note}
	The letter $e$ denotes an environment. \\
	The symbol $\_$ is used whenever a value exists but is content is irrelevant
	to the semantical rule, or cannot be determined and therefore is discarded.
\end{note}

\textbf{Dictionaries}

\begin{gather*}
	\te{Creation} \\
	\hline \\
	<\te{e, d}> \Rightarrow \\ \{ (k,v) \in d \mid \forall i,j \in \N \wedge i,j \in \left[1, \abs{d}\right] \land i \neq j \\ \text{such that } k_i \neq k_j \}
\end{gather*}
\begin{gather*}
	\te{Insertion} \\
	\hline \\
	\dfrac{ \begin{aligned}
		<\te{e, d}> \Rightarrow \te{ed} \\
		<\te{e, k} \in \te{ed}> \Rightarrow \te{false} \\
	\end{aligned} }{<\te{e, insert k v d}> \Rightarrow \te{ed} \cup (\te{k,v})} \\ \\
	\dfrac{ \begin{aligned}
		<\te{e, d}> \Rightarrow \te{ed} \\
		<\te{e, k} \in \te{ed}> \Rightarrow \te{true}
	\end{aligned}}{<\te{e, insert k v d}> \Rightarrow \te{ed} \textbackslash \{(\te{k,\_})\} \cup (k, v) }
\end{gather*}
\begin{gather*}
	\te{Deletion} \\ \hline \\
	\dfrac{	\begin{aligned}
		<\te{e, d}> \Rightarrow \te{ed} \\
		<\te{e, k} \in \te{ed}> \Rightarrow \te{true}
	\end{aligned}}{<\te{e, remove k d}> \Rightarrow \te{ed} \textbackslash \{(\te{k,v})\}} \\ \\
	\dfrac{	\begin{aligned}
		<\te{e, d}> \Rightarrow \te{ed} \\
		<\te{e, k} \in \te{ed}> \Rightarrow \te{false}
	\end{aligned}}{<\te{e, remove k d}> \Rightarrow \te{error}}
\end{gather*}
\begin{gather*}
	\te{Contains key} \\ \hline \\
	\dfrac{<\te{e, d}> \Rightarrow \te{ed}}{<\te{e}, \te{haskey k d}> \Rightarrow (\te{k, \_}) \in \te{ed}}
\end{gather*}
\begin{gather*}
	\te{Retreive a value} \\ \hline \\
	\dfrac{	\begin{aligned}
		<\te{e, d}> \Rightarrow \te{ed} \\
		<\te{e, k} \in \te{ed}> \Rightarrow \te{true}
	\end{aligned}}{<\te{e, getkey k d}> \Rightarrow \te{v}} \\ \\
	\dfrac{	\begin{aligned}
		<\te{e, d}> \Rightarrow \te{ed} \\
		<\te{e, k} \in \te{ed}> \Rightarrow \te{false}
	\end{aligned}}{<\te{e, getkey k d}> \Rightarrow \te{error}}
\end{gather*}
\begin{gather*}
	\te{Filter by keys} \\ \hline \\
	\dfrac{	\begin{aligned}
		<\te{e, d}> \Rightarrow \te{ed} \\
		<\te{e, ks}> \Rightarrow \te{\{k1, ..., kn\}}
	\end{aligned}}{<\te{e, filterkeys ks d}> \Rightarrow \{ (k, v) \in \te{ed} \mid (k \in ks) \}}
\end{gather*}
\begin{gather*}
	\te{Map} \\ \hline \\
	\dfrac{	\begin{aligned}
		<\te{e, d}> \Rightarrow \te{ed} \\
		<\te{e, f}> \Rightarrow \lambda(x)
	\end{aligned}}
	{<\te{e, map f d}> \Rightarrow \{ (k, \lambda(v)) \mid (k, v) \in \te{ed}  \}}
\end{gather*}
\begin{gather*}
	\te{Fold Left} \\ \hline \\
	\dfrac{\begin{aligned}
		<\te{e, f}> \Rightarrow \lambda(x,y)  \\
		<\te{e, d}> \Rightarrow \{(k_1, v_1), \hdots, (k_n, v_n)\}
	\end{aligned}}{<\te{e, foldl f a d}> \Rightarrow \lambda( \hdots \lambda(\lambda(a, v_1), v_2), \hdots, v_n)} \\ \\
\end{gather*}

\fi

\clearpage

\begin{appendices}
  \section{Parsing Grammar}
  \label{grammar}
  \lstinputlisting[style=txt]{grammar.txt}
\end{appendices}


\bibliography{bib}

\end{document}
