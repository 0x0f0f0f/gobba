\documentclass[a4paper, 10pt]{article}

%% Language and font encodings. This says how to do hyphenation on end of lines.
\usepackage[english]{babel}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{mathtools}
\usepackage{amsthm}
\usepackage{collectbox}
%\usepackage{tgpagella} % text only
%\usepackage{mathpazo}
\usepackage{stix2}

\usepackage{multicol}
\setlength{\columnsep}{1.5cm}
\setlength{\columnseprule}{0.5pt}
%\usepackage{aas_macros}

%% Sets page size and margins. You can edit this to your liking
\usepackage[top=1.3cm, bottom=2.0cm, outer=2.5cm, inner=2.5cm, heightrounded,
marginparwidth=1cm, marginparsep=0.4cm, margin=1.2cm]{geometry}

%% Useful packages
\usepackage{graphicx} %allows you to use jpg or png images. PDF is still recommended
\usepackage[colorlinks=False]{hyperref} % add links inside PDF files
\usepackage{amsmath}  % Math fonts
\usepackage{amsfonts} %
\usepackage{amssymb}  %

\definecolor{vgreen}{RGB}{104,180,104}
\definecolor{vblue}{RGB}{49,49,255}
\definecolor{vorange}{RGB}{255,143,102}
\lstdefinestyle{bash} {language=bash, basicstyle=\ttfamily,
	keywordstyle=\color{vblue}, identifierstyle=\color{black},
	commentstyle=\color{vgreen}, tabsize=4,
%	moredelim=*[s][\colorIndex]{[}{]},
	literate=*{:}{:}1}

\lstdefinestyle{caml} {language=caml, basicstyle=\ttfamily, columns=[c]fixed,
 keywordstyle=\color{vblue}, identifierstyle=\color{black},
 commentstyle=\color{vgreen}, upquote=true, commentstyle=, breaklines=true,
 showstringspaces=false, stringstyle=\color{blue},
 literate={'"'}{\textquotesingle "\textquotesingle}3}

\lstdefinestyle{txt} {basicstyle=\ttfamily, columns=[c]fixed,
 keywordstyle=\color{vblue}, identifierstyle=\color{black},
 commentstyle=\color{vgreen}, upquote=true, commentstyle=, breaklines=true,
 showstringspaces=false, stringstyle=\color{blue},
 literate={'"'}{\textquotesingle "\textquotesingle}3}


%% Citation package
%\usepackage[authoryear]{natbib}
\bibliographystyle{unsrt}
%\setcitestyle{authoryear,open={(},close={)}}

\newcommand{\te}[1]{\text{#1}}
\newcommand{\mybox}{%
    \collectbox{%
        \setlength{\fboxsep}{1pt}%
        \fbox{\BOXCONTENT}%
    }%
}
\def\C{\mathbb{C}}
\def\N{\mathbb{N}}
\def\Q{\mathbb{Q}}
\def\R{\mathbb{R}}
\def\Z{\mathbb{Z}}
\DeclarePairedDelimiter\abs{\lvert}{\rvert}

\theoremstyle{plain}% default
\newtheorem{thm}{Theorem}[section]
\newtheorem{lem}[thm]{Lemma}
\newtheorem{prop}[thm]{Proposition}
\newtheorem*{cor}{Corollary}
\theoremstyle{definition}
\newtheorem{defn}{Definition}[section]
\newtheorem{conj}{Conjecture}[section]
\newtheorem{exmp}{Example}[section]
\newtheorem{exrc}[exmp]{Exercise}
\theoremstyle{remark}
\newtheorem*{comm}{Comment}
\newtheorem*{note}{Note}
\newtheorem{caso}{Case}

\title{Minicaml, a purely functional, didactical programming language\\WORK IN PROGRESS DRAFT}
\author{Alessandro Cheli\\Course taught by Prof. Gianluigi Ferrari\\and Prof. Francesca Levi}

\begin{document}
\maketitle

\begin{abstract}
\textbf{minicaml} is a dinamically typed and purely functional interpreted
programming language. It is based on the Professor Gianluigi Ferrari and
Professor Francesca Levi's minicaml, an evaluation example to show students
attending the Programming 2 course at the University of Pisa how interpreters
work. It is an interpreted language heavily inspired from the OCaml, Haskell and
Scheme languages, with static (lexical scoping), eager and lazy evaluation and a
didactical REPL that shows each AST expression and each evaluation step.
\end{abstract}

\section{REPL and command line interface}
\subsection{Installation}
\textbf{minicaml} is available in the opam 2.0 repository.
(\url{https://opam.ocaml.org/}). The easiest way to install minicaml is with the
OCaml package manager \textbf{opam}. To do so, please check that you have a version of opam $\geq$
2.0.0 and run:
\begin{lstlisting}[style=bash]
opam install minicaml
\end{lstlisting}
Alternatively, \textbf{minicaml} can be installed from source by downloading the
source code repository and building it manually. \textbf{minicaml} has been tested
only on Linux and macOS systems. It has not been tested yet on Windows and BSD
derived systems.
\begin{lstlisting}[style=bash]
# download the source code
git clone https://github.com/0x0f0f0f/minicaml
# cd into the source code directory
cd minicaml
# install dependencies
opam install ANSITerminal dune ppx_deriving menhir \\
  cmdliner alcotest bisect_ppx ocamline
# compile
make
# test
make test
# execute
make run
# install
make install
\end{lstlisting}

\clearpage

\begin{multicols}{2}

\section{Syntax and Parser}
Lexing is achieved with \texttt{ocamllex}, the default tool for generating
scanners in OCaml.
The parser is realized with the \textbf{Menhir} parser generator, and is
documented using \textbf{Obelisk}, which generates a clean text file
containing the language grammar, available in Appendix \ref{grammar}.

\section{Purity Inference}
An important feature of the minicaml language is the purity inference algorithm,
which is performed statically on expressions before evaluation. It is an
interpretation of expressions over the domain of purity, meant to prevent side
effects by signal an error if they are contained inside the programs written in
the language. Expressions are tagged by the algorithm with the \texttt{Pure},
\texttt{Impure} and \texttt{Numerical} labels. An \texttt{Impure} expression is
an expression that contains calls to primitives that perform I/O operations,
mutable variables and/or imperative style assignments. A \texttt{Numerical}
expression is an expression where only numerical operations are performed.
\texttt{Pure} expressions are those which do not fall into the previous two
categories. To perform impure side effects, the programmer has two constructs
available called \textbf{purity blocks}. By default, the evaluator is in an
\texttt{Uncertain} context, which means that it will not allow side effects to
be carried on by evaluation, but will allow evaluating purity blocks that change
the currently allowed purity context. The \texttt{impure} statement takes an
expression (the block) and evaluates it in a context where the allowed purity is
\texttt{Impure}, so that side effects may be performed. The other construct
available, the \texttt{pure} statement, takes an expression and enforces a
\texttt{Pure} context, meaning that side effects and nested impure blocks will
not be allowed inside of the expression.

\section{AST Optimization}
After purity inference is performed, and before evaluation, AST expressions are analyzed and optimized by an
optimizer function that is recursively called over the tree that is representing
the expression. The optimizer simplifies expressions which result is known and
therefore does not need to be evaluated. For example, it is known that \texttt{5
+ 3 $\equiv$ 8} and \texttt{true \&\& (true || (false \&\& false)) $\equiv$
true}. When a programmer writes a program, she or he may not want to do all the
simple calculations before writing the program in which they appear in, we rely
on machines to simplify those processes. Reducing constants before evaluation
may seem unnecessary when writing a small program, but they do take away
computation time, and if they appear inside of loops, it is a wise choice to
simplify those constant expressions whose result is already known before it is
calculated in all the loop iterations. It is also necessary in optimizing
programs before compilation. The optimizer, by now, reduces operations between
constants and \texttt{if} statements whose guard is always true (or false). To
achieve minimization to an unreducible form, optimizer calls are repeated until
it produces an output equal to its input; this way, we get a tree representing
an expression that cannot be optimized again. This process is fairly easy:

\begin{lstlisting}[style=caml]
let rec iterate_optimizer e =
  let oe = optimize e in
  if oe = e then e (* Bottoms out *)
  else iterate_optimizer oe
\end{lstlisting}

Boolean operations are reduced using laws from the propositional calculus, such as DeMorgan's law, complement, absorption and other trivial ones.

\section{Types}

\section{Evaluation}
\texttt{minicaml}'s evaluator is heavily inspired by the Metacircular Evaluator defined in the highly acclaimed textbook \textit{Structure and Interpretation of Computer Programs} \cite{Abelson1996}
\subsection{Operational Semantics}

\begin{note}
	The letter $e$ denotes an environment. \\
	The symbol $\_$ is used whenever a value exists but is content is irrelevant
	to the semantical rule, or cannot be determined and therefore is discarded.
\end{note}


\textbf{Dictionaries}

\begin{gather*}
	\te{Creation} \\
	\hline \\
	<\te{e, d}> \Rightarrow \\ \{ (k,v) \in d \mid \forall i,j \in \N \wedge i,j \in \left[1, \abs{d}\right] \land i \neq j \\ \text{such that } k_i \neq k_j \}
\end{gather*}
\begin{gather*}
	\te{Insertion} \\
	\hline \\
	\dfrac{ \begin{aligned}
		<\te{e, d}> \Rightarrow \te{ed} \\
		<\te{e, k} \in \te{ed}> \Rightarrow \te{false} \\
	\end{aligned} }{<\te{e, insert k v d}> \Rightarrow \te{ed} \cup (\te{k,v})} \\ \\
	\dfrac{ \begin{aligned}
		<\te{e, d}> \Rightarrow \te{ed} \\
		<\te{e, k} \in \te{ed}> \Rightarrow \te{true}
	\end{aligned}}{<\te{e, insert k v d}> \Rightarrow \te{ed} \textbackslash \{(\te{k,\_})\} \cup (k, v) }
\end{gather*}
\begin{gather*}
	\te{Deletion} \\ \hline \\
	\dfrac{	\begin{aligned}
		<\te{e, d}> \Rightarrow \te{ed} \\
		<\te{e, k} \in \te{ed}> \Rightarrow \te{true}
	\end{aligned}}{<\te{e, remove k d}> \Rightarrow \te{ed} \textbackslash \{(\te{k,v})\}} \\ \\
	\dfrac{	\begin{aligned}
		<\te{e, d}> \Rightarrow \te{ed} \\
		<\te{e, k} \in \te{ed}> \Rightarrow \te{false}
	\end{aligned}}{<\te{e, remove k d}> \Rightarrow \te{error}}
\end{gather*}
\begin{gather*}
	\te{Contains key} \\ \hline \\
	\dfrac{<\te{e, d}> \Rightarrow \te{ed}}{<\te{e}, \te{haskey k d}> \Rightarrow (\te{k, \_}) \in \te{ed}}
\end{gather*}
\begin{gather*}
	\te{Retreive a value} \\ \hline \\
	\dfrac{	\begin{aligned}
		<\te{e, d}> \Rightarrow \te{ed} \\
		<\te{e, k} \in \te{ed}> \Rightarrow \te{true}
	\end{aligned}}{<\te{e, getkey k d}> \Rightarrow \te{v}} \\ \\
	\dfrac{	\begin{aligned}
		<\te{e, d}> \Rightarrow \te{ed} \\
		<\te{e, k} \in \te{ed}> \Rightarrow \te{false}
	\end{aligned}}{<\te{e, getkey k d}> \Rightarrow \te{error}}
\end{gather*}
\begin{gather*}
	\te{Filter by keys} \\ \hline \\
	\dfrac{	\begin{aligned}
		<\te{e, d}> \Rightarrow \te{ed} \\
		<\te{e, ks}> \Rightarrow \te{\{k1, ..., kn\}}
	\end{aligned}}{<\te{e, filterkeys ks d}> \Rightarrow \{ (k, v) \in \te{ed} \mid (k \in ks) \}}
\end{gather*}
\begin{gather*}
	\te{Map} \\ \hline \\
	\dfrac{	\begin{aligned}
		<\te{e, d}> \Rightarrow \te{ed} \\
		<\te{e, f}> \Rightarrow \lambda(x)
	\end{aligned}}
	{<\te{e, map f d}> \Rightarrow \{ (k, \lambda(v)) \mid (k, v) \in \te{ed}  \}}
\end{gather*}
\begin{gather*}
	\te{Fold Left} \\ \hline \\
	\dfrac{\begin{aligned}
		<\te{e, f}> \Rightarrow \lambda(x,y)  \\
		<\te{e, d}> \Rightarrow \{(k_1, v_1), \hdots, (k_n, v_n)\}
	\end{aligned}}{<\te{e, foldl f a d}> \Rightarrow \lambda( \hdots \lambda(\lambda(a, v_1), v_2), \hdots, v_n)} \\ \\
\end{gather*}

\section{Tests}
Unit testing is extensively performed using the alcotest testing framework. Code
coverage is provided by the \texttt{bisect\_ppx} library which yields an HTML
page containing the coverage percentage when unit tests are run by the dune
build system. After each commit is pushed to the remote version control repository on
Github, the package is built and tests are run thanks to the Travis Continuos
Integration system.

\section{Thanks to}

\begin{itemize}
	\item Prof. Gian-Luigi Ferrari and Francesca Levi for teaching us how to project and develop
	interpreters in OCaml
	\item Antonio DeLucreziis for helping me implement lazy evaluation.
	\item Prof. Alessandro Berarducci for helping me study lambda calculus in deep.
	\item Giorgio Mossa for helping me polish the lambda-closure mechanism.
\end{itemize}

\end{multicols}

\appendix
\clearpage
\section{Parsing Grammar}
\label{grammar}

\lstinputlisting[style=txt]{grammar.txt}

\bibliography{bib}

\end{document}
